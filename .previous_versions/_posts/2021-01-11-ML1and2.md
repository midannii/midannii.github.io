---
layout: post
title:  "[ML/DL] Overall Machine Learning - 핸즈온 머신러닝 Chap 1,2"
date:   2021-01-11
desc: " "
keywords: "DL, ML"
categories: [Deeplearning]
tags: [DL, ML, tensorflow]
icon: icon-html
---

# OverAll Machine Learning



## 1. 종류


### 1) Supervised Deeplearning

training data에 label이라는 답지가 포함됨

e.g. k-nearest neighbors, linear regression, logistic regression, SVM, desicion tree, random forest, neural network ..



### 2) Unsupervised Deeplearning

training data에 label 없음

e.g. k-menas clustering, DBSCAN, HCA, outliers detection, novelty detection, one-class SVM, isolation forest, PCA< LLE, t-SNE, Apriori, Eclat ...


 + t-SNE: 의미있는 군집을 강조

 + 차원 축소: 상관관계가 있는 여러 feature를 하나로 합쳐 feature extraction

 + outlier detection: 학습 알고리즘에 dataset를 주입하기 전에 이상한 값을 자동으로 제거

 + association rule learning: 대량의 데이터에서 특성 간의 흥미로운 관계를 찾음


### 3) Semisupervised Deeplearning

일부만 label이 있음. 주로 supervised와 unsupervised의 조합으로 이루어짐

e.g. DBN



### 4) Reinforcement learning

임의의 존재 (Agent) 가 주어진 환경 내에서 어떻게 행동해야 하는지에 대해 학습하는 것

학습 과정에서 보상과 벌점을 받으며, 가장 큰 보상을 얻기 위해 policy를 스스로 학습



## 2. 기본적인 용어


### 1) batch vs minibatch



#### (1)batch Learning

주로 오프라인에서 수행됨(가용한 데이터를 모두 사용해 훈련시켜야 하므로, 시간과 자원이 많이 소모되기 때문 )

먼저 system을 학습시키고, 제품 system에 적용하는 offline Learning




#### (2) online Learning (점진적 학습)

데이터를 순차적으로 한개씩 or 작은 묶음 단위(`mini-batch`)로 주입하여 전체 데이터를 적용할 때까지 system을 훈련시킴

학습이 빠르고 비용이 적게듦

연속적으로 data를 받고, 빠른 변화에 스스로 적응해야 하는 system이나

자원이 제한된 경우, 아주 큰 dataset을 학습시키는 데에 좋음

but, 나쁜 데이터가 들어오면 system 성능이 점진적으로 감소

### 2) Learning rate

online learning에서 변화하는 data에 얼마나 빠르게 적응할지를 결정

- 높은 경우, system이 데이터에 빨리 적응하지만, 예전 데이터 금방 잊어버림

- 낮은 경우, 느리게 학습됨


### 3) 사례기반 vs 모델기반 학습


#### (1) 사례 기반 학습

system이 훈련 sample을 기억하고, 유사도 측정을 통해 새로운 데이터와 학습한 sample 비교

e.g. k-nearest neighbor

#### (2) 모델 기반 학습

sample들의 모델을 만들어 예측에 이용

e.g. Linear regression

- 효용함수(적합도 함수): 모델이 얼마나 좋은지를 측정

- 비용함수(cost funtion): 모델이 얼마나 나쁜지를 측정


## 3. 검증 방법

training data와 test data로 나누어 각각 훈련과 테스트를 진행

이때 새로운 sample에 대한 오류 비율을 `일반화 오차(generalization error)` 로 두고, 훈련 오차가 낮지만 일반화오차가 높으면 overfitting 되어있다고 판단 가능

`hold-out validation`을 통해, training dataset의 일부를 떼어내어 다양한 hyperparameter를 갖는 여러 후보 모델을 평가하고, 가장 좋은 하나를 선택하기도 함

`cross-validation`을 통해 dataset 여러개를 사용해 더 정확한 성능 측정 가능(but, 훈련 시간 증가)



## 4. 성능 측정 지표

regression의 경우 [RMSE(root mean square error)](https://ko.wikipedia.org/wiki/%ED%8F%89%EA%B7%A0_%EC%A0%9C%EA%B3%B1%EA%B7%BC_%ED%8E%B8%EC%B0%A8) 많이 이용 (커질수록 예측의 오류 큼)

그 외에도 [MSE(mean square error)](https://wikidocs.net/34063), [MAE(mean absolute error)](https://en.wikipedia.org/wiki/Mean_absolute_error) 이용하여 예측값과 실제값을 비교


## 5. workflow


```

 1. 환경 세팅
 2. 데이터 다운로드
 3. head()와 describe()로 데이터 훑어보기
 4. train 과 test로 dataset 나누기 (with split_train_test())
  - 이때, 일부 알고리즘은 training sample의 순서에 따라 성능이 달라질수도 있기 때문에(비슷한 sample이 연속으로 나타날때 등) random-shuffle 해줘야 함 
 5. EDA - plot 그려서 확인, 각 feature간의 correlation 확인
 6. 데이터 정제
  + categorical, 또는 Ordinal data의 경우 별도의 encoder 적용
  + feature scaling (min-max, normalization)
 7. 모델 선택, 훈련
 8. 교차 검증(k-fold cross-validation)
 9. 모델 세부 튜닝 : 최적의 parameter를 찾기 (gridSearch, RandomizeSearch, Ensemble, ...)
 10. 평가
```

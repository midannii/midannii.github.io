---
layout: post
title:  "[NLP] TF-IDF란 ?  "
date:   2021-01-17
categories: NLP
---

<br>

## Definiton

자연어처리에서 자주 사용되는 `tf-idf` !

이 정의를 알기 위해서는 각 알파벳이 뭐의 약어인지를 살펴보자.


<br>

우선 `TF`는 term frequency. 즉 특정한 단어가 문서 내에 얼마나 자주 등장하는지를 나타내는 값이다.

값이 높을수록 문서에서 중요하다고 생각할 수 있지만 단어 자체가 문서군 내에서 자주 사용 되는 경우, 그 단어가 흔하게 등장한다는 것을 의미한다.

`DF`는 document frequency, 이 값의 역수를 `IDF` 즉 inverse document frequency라고 한다.

(DF가 아니라 IDF를 쓰는 이유는 가장 DF가 큰 값을 1이 되도록 하여 확률값으로 처리하기 위함이다. IDF를 확률값으로 처리)

IDF 값은 문서군의 성격에 따라 결정된다.

예를 들어 '원자'라는 낱말은 일반적인 문서들 사이에서는 잘 나오지 않기 때문에 IDF 값이 높아지고 문서의 핵심어가 될 수 있지만,

원자에 대한 문서를 모아놓은 문서군의 경우 이 낱말은 상투어가 되어 각 문서들을 세분화하여 구분할 수 있는 다른 낱말들이 높은 가중치를 얻게 된다.



![fig](https://deeplearning4j.org/img/tfidf.png)


`TF-IDF`는 TF와 IDF를 곱한 값으로 점수가 높은 단어일수록 다른 문서에는 많지 않고 해당 문서에서 자주 등장하는 단어를 의미한다

또한 다른 문서에서 등장하면 단어의 중요성이 하락한다는 뜻이 된다.


<br>

즉 정리하면 TF-IDF는 여러 개의 문서가 있을 때 각각의 문서의 내에 있는 단어들에 가중치를 적용하여 수치값을 주는 방법이다.

TF-IDF를 계산하면 문서 내에 상대적으로 중요한 단어를 알 수 있다.

문서간 유사도를 구하기 위한 코사인 유사도를 구하거나 Clustering를 적용하기 전에 문서 내에 단어들에 수치값을 부여하게 된다.


<br>

기존 CountVectorizer는 단어의 빈도수를 기반으로 하기 때문에, 조사, 관사 등의 의미 없는 단어에 높은 수치를 부여할 수 있다는 한계점이 존재한다.

TF-IDF를 사용하면 이러한 단점을 보완할 수 있다.

<br>

# How to use?

python의 Scikit-Learn 라이브러리를 사용한다.

```python
from sklearn.feature_extraction.text import TfidfVectorizer
X = ['Which do you like apple or banana?','I love apple tree in the yard.','Lets make an apple jam.']
tfidf_vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf_vectorizer.fit_transform(X)
```

이때, nltk의 stopwords(불용어)는 미리 받아두어야 한다.


```python
tfidf_vectorizer.fit(text) # 단어를 학습시킴
tfidf_vectorizer.vocabulary_ # 단어사전을 출력
sorted(tfidf_vectorizer.vocabulary_.items()) # 단어사전 정렬
tfidf_vectorizer.idf_ # IDF 벡터화의 결과물 확인
tfidf_vectorizer.transform(text).toarray() # TF-IDF 벡터화의 최종 결과물
```





<br>

## reference

- https://medium.com/@nsh235482/tf-idf-term-frequency-inverse-document-frequency-algorithm-55f64714880d

- https://nesoy.github.io/articles/2017-11/tf-idf

- https://wikidocs.net/31698

- https://m.blog.naver.com/duqrlwjddns1/221780750830

---
layout: post
title:  "[ëª¨ë‘ë¥¼ ìœ„í•œ ë”¥ëŸ¬ë‹2 Pytorch] Logistic Regression  "
date:   2021-01-14
desc: " "
keywords: "DL, ML"
categories: [Deeplearning]
tags: [DL, ML, pytorch]
icon: icon-html
---

ğŸ³ reference: <ëª¨ë‘ë¥¼ ìœ„í•œ ë”¥ëŸ¬ë‹ 2: pytorch> Lab5

logistic regressionì˜ ê²½ìš°ì—ë„, ì´ë¡ ì€ ì •ë¦¬í•´ ë‘ì—ˆìœ¼ë‹ˆ pytorch ì‹ ìœ„ì£¼ë¡œ ì‚´í´ë³´ì

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
```

<br>

## Hypothesis

ì˜ˆë¥¼ ë“¤ì–´, data Xê°€ (mê°œì˜ sample, dì°¨ì›) ìˆì„ë•Œ,

ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 0ê³¼ 1ë¡œ ì´ë£¨ì–´ì§„ mê°œì˜ ì •ë‹µë“¤ì„ predict í•´ì•¼í•œë‹¤.

(ì´ì™€ ê°™ì€ binary classificationì˜ ê²½ìš° 1ì¼ í™•ë¥ ê³¼ 0ì¼ í™•ë¥ ì˜ í•©ì€ 1ì´ ëœë‹¤)



![fig](https://render.githubusercontent.com/render/math?math=H%28X%29%20%3D%20%5Cfrac%7B1%7D%7B1%2Be%5E%7B-W%5ET%20X%7D%7D&mode=display)

## Cost function

![fig](https://render.githubusercontent.com/render/math?math=cost%28W%29%20%3D%20-%5Cfrac%7B1%7D%7Bm%7D%20%5Csum%20y%20%5Clog%5Cleft%28H%28x%29%5Cright%29%20%2B%20%281-y%29%20%5Cleft%28%20%5Clog%281-H%28x%29%20%5Cright%29&mode=display)

![fig](https://render.githubusercontent.com/render/math?math=W%20%3A%3D%20W%20-%20%5Calpha%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20W%7D%20cost%28W%29&mode=display)


ì´ë•Œ yê°€ H(x)ì™€ ë¹„ìŠ·í• ìˆ˜ë¡ cost funtionì´ 0ì— ê°€ê¹ë‹¤.

ë§ˆì§€ë§‰ìœ¼ë¡œ `sigmoid í•¨ìˆ˜`ë¥¼ í†µí•´ binary classificationì„ ì™„ë£Œí•œë‹¤


![fig](https://miro.medium.com/max/3268/1*a04iKNbchayCAJ7-0QlesA.png)



<br>

codeëŠ” ì•„ë˜ì™€ ê°™ë‹¤


```python
x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]] # (6,2)ì˜ ë°ì´í„°
y_data = [[0], [0], [0], [1], [1], [1]] # (6,)ì˜ ë°ì´í„°
x_train = torch.FloatTensor(x_data)
y_train = torch.FloatTensor(y_data)

# ëª¨ë¸ ì´ˆê¸°í™”
W = torch.zeros((2, 1), requires_grad=True) # zero gradientë¡œ ê¼­ ì´ˆê¸°í™” í•´ì¤˜ì•¼ í•¨
b = torch.zeros(1, requires_grad=True)
# optimizer ì„¤ì •
optimizer = optim.SGD([W, b], lr=1)

nb_epochs = 1000
for epoch in range(nb_epochs + 1):

    # Cost ê³„ì‚° - sigmoid ì´ìš©
    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @
    cost = -(y_train * torch.log(hypothesis) +
             (1 - y_train) * torch.log(1 - hypothesis)).mean()

    # costë¡œ H(x) ê°œì„  - backpropagation
    optimizer.zero_grad()
    cost.backward()
    optimizer.step()

    # 100ë²ˆë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
    if epoch % 100 == 0:
        print('Epoch {:4d}/{} Cost: {:.6f}'.format(
            epoch, nb_epochs, cost.item()
        ))

```

ë˜ëŠ” `cost = F.binary_cross_entropy(hypothesis, y_train)` ë¥¼ ëŒ€ì‹  ì¨ì„œ binary_cross_entropyë¥¼ ê³„ì‚°í• ìˆ˜ë„ ìˆë‹¤.


<br>

## Evaluation

ì•„ë˜ì™€ ê°™ì´ ì„±ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆë‹¤.


```python
hypothesis = torch.sigmoid(x_train.matmul(W) + b)
prediction = hypothesis >= torch.FloatTensor([0.5])
correct_prediction = prediction.float() == y_train

accuracy = correct_prediction.sum().item() / len(correct_prediction)
print('The model has an accuracy of {:2.2f}% for the training set.'.format(accuracy * 100))
```

<br>


`module.nn`ì„ ì´ìš©í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤


```python
class BinaryClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(8, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        return self.sigmoid(self.linear(x))
```


ìœ„ì™€ ê°™ì€ ê²½ìš°, WëŠ” (8,1)ì´ê³ , b = (8,) ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤

ì¦‰, mì˜ ê°’ì€ ëª¨ë¥´ì§€ë§Œ dëŠ” 8ì¸ ê²ƒì´ë‹¹


<br>

```python    
model = BinaryClassifier()

# optimizer ì„¤ì •
optimizer = optim.SGD(model.parameters(), lr=1)

nb_epochs = 100
for epoch in range(nb_epochs + 1):

    # H(x) ê³„ì‚°
    hypothesis = model(x_train)

    # cost ê³„ì‚°
    cost = F.binary_cross_entropy(hypothesis, y_train)

    # costë¡œ H(x) ê°œì„ 
    optimizer.zero_grad()
    cost.backward()
    optimizer.step()

    # 20ë²ˆë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
    if epoch % 10 == 0:
        prediction = hypothesis >= torch.FloatTensor([0.5])
        correct_prediction = prediction.float() == y_train
        accuracy = correct_prediction.sum().item() / len(correct_prediction)
        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format(
            epoch, nb_epochs, cost.item(), accuracy * 100,
        ))
```

---
layout: post
title:  "[NLP/Graph/Numerical Reasoning/QA]Question Directed Graph Attention Network for Numerical Reasoning over Text"
date:   2021-11-20
categories: PaperReview
---

## * 요약

- deep learning과 graph reasoning combine한 모델인 QDGAT model 제안
    - numerical reasoning에 필요한 passage, question 의 context에 대한 heterogeneous graph representation 제안
    - context graph에 대해 multi-step numerical reasoning를 유도하기 위한 question-directed graph attention network임

---

## 1. Introduction

- 기존 numerical reasoning model인 NAQANet은 숫자들 사이의 상대 크기를 고려하지 않음

    → 이를 해결하기 위해, 그래프를 사용한 NumNet 제안

    → 그러나, 두가지가 부족함

    1. number type and entity mention
        - 숫자 이해와 추론에 필수적인 역할을 함
        - 숫자 비교, 덧셈, 뺄셈은 일반적으로 동일한 유형을 사용하거나, 동일한 entity를 참조함
    2. direct interaction with question
- example with table1 and figure 1
    - 예시 1) population counting
        - q의 entity는 p의 여러 문장에서 나타날 수 있으며, 이러한 bridging entities를 통해 각 숫자가 서로 어떻게 관련되어 있는지를 나타냄

            → QA 모델이 numerical reasoning을 위해 정보를 더 잘 수집하고 집계하는 데 도움됨

        - q의 entity가 단일 문장(이 예의 마지막 문장)에서 동시에 발생하는 경우 해당 문장에서 답을 도출할 수 있음
    - 예시 2) span extraction
        - model은 숫자와 q entity의 correlation이 명시적으로 제공될 때만 유용함
- 본 논문에서는
    - type, entity information이 model에 명시적으로 통합되기 위해 heterogeneous directed graph를 구성함
        - 이 그래프에서는 node, entity가 다른 type의 숫자로 구성되고, edge가 다른 유형의 relation을 encoding할 수 있음

            (숫자 type이 다르다는 것; e.g. 일반숫자와 percentage ... )

    - heterogeneous directed graph를 기반으로 numerical MRC를 수행하는 question directed graph attention network (`QDGAT`) 제안
        - `QDGAT` learns to collect information from the graph conditioned on the question for numerical reasoning.
        - BERT, RoBERTa와 같은 context encoder를 사용하여 Q,P에서 숫자, entity representation을 추출

            → 그래프에서의 initial embedding 역할

- `QDGAT` 는
    - QDGAT는 그래프를 통해, numerical reasoning를 위한 Q에서 정보를 수집하는 방법을 학습함
        - 그래프에서, 각 node는 Q에 대한 context-aware representation임
            - 이때, representation은 message-passing iteration에서 update됨
        - message-passing iteration이 반복된 후, QDGAT는 Q에 대답하기 위해 node information을 점진적으로 집계함
    - P,Q의 representation을 추상화하여, 모델이 해석가능한 reasoning pattern을 생성하도록 함
    - DROP, RACE dataset(중에서 number-related question갖는 애들만) 으로 evaluation (DROP에서 SOTA임 )

## 2. Related Work

## 3. Methods

![Untitled](https://d3i71xaburhd42.cloudfront.net/387d59877a641815d79516a7264ff5d20384c596/4-Figure2-1.png)

### 3.1. Problem Definition

passage를 기반으로 answer the question (sorting, counting, addition, subsection과 같은 numerical reasoning을 수행)

### 3.2. Overall Framework

three main components;

- a representation extractor module
    - 입력된 숫자 및 관련 entity가 있는 heterogeneous graph를 구성함
    - textual input의 representation을 위해, base architecture로 RoBERTa (encoder)
    - The graph `G = (V, E)` contains numbers N and entities T as the nodes `V = {N, T}`, and its edges E encode the information of the number type and the relationship between the numbers and the entities.
- a reasoning module
    - representation (Mp, Mq), question command c를 계산

        → 이를 바탕으로 QDGAT가 추론함 (U를 계산)

- a prediction module
    - 대답의 유형 3가지에 대해, 각각의 Module을 구현

        (a) span extraction ; single span, multi span, single question span

        (b) count ; drop dataset의 97%가 10-class classification problem (0-9)로 간주됨

        (c) arithmetic expression ; 각 숫자를 -1, 0, +1중 하나로 분류하여 산술 계산을 통해 도출함.  addition, subtraction operations만 포함


### 3.3. Graph contruction with Typed Number and Enties

- 단순히 directed edge로 수치비교만 수행한 NumNet과 달리, QDGAT는 수치 비교를 modeling하지 않고 number type, related entity를 활용함
- 각 node는 entities T와 numbers N로 이루어져 있음 ; 외부의 NER system에 의해 인식됨
    - NER system은 text의 각 token을 category로 분류; NUMBER, PERCENT, MONEY, TIME, DATE, DURATION, ORDINAL 등은 NUMBER로 간주
    - DROP에는 american football 내용이 많아서, YARD 유형의 숫자를 추출하기 위해 heuristic rules 적용
    - number extractor(word2num)을 사용하여 남아있는 숫자를 모두 추출하여 NUMBER로 labeling함

    → 이러한 number token은 VN =(NUMBER,PERCENT,MONEY,TIME,DATE, DURATION, ORDINAL, YARD)으로 구성

    - 이 외의 token은 ENTITY label에 mapping하여 entity 집합 T를 만듦

    → 이러한 entity type information은 모델에 직접 질문과 관련된 숫자를 찾도록 알려주므로 reasoning의 어려움을 줄일 수 있음

- edge는 두가지 상황에 해당하는 number,entity간의 relation을 encoding함
    1. The edge between the numbers ; ri,j = rj,i는 number type임, 두 숫자가 동일한 type일때에만 edge가 존재함
    2. The edge between the entity and the number ; ri,j = rj,i =  ENT+DIGIT

### 3.4. Question Directed Graph Attention Network (`QDGAT`)

- QDGAT는 number와 entity 간의 message passing을 여러 번 반복하여, relational information를 수집하는 질문을 condition로 하는 `context-aware numerical reasoning`을 만듦

    → 이를 위해 contextualized question representation으로 reasoning module을 보강함

    - 숫자, entity를 찾아 graph로 modeling되고, 숫자에 대해 reasoning하여 answer계산을 위한 expression을 도출함
- graph neural network는 extractor에서 얻은 representation을 input으로 함
- 각각 t번째 iteration에서,
    - `question directed layer`는 노드 임베딩 representation과 question information을 통합함 (reasoning step을 모방함)
    - c; node(즉, number와 entity) 간의 정보 전파를 지시하는 데 사용됨
        - 각 node는 question command로 이웃으로부터 정보를 수집함 (숫자와 entity의 역할은 입력 자체뿐만 아니라 neighbot과 이들 간의 relation에 따라 달라짐)
            - 모든 relation을 요약하여, node i, j사이의 relation을 계산함 (with leakyReLU)

                → 이러한 attention score는 이웃 Node에서의 정보 수집을 위한 message propagation에 사용됨

                → node embedding update, graph attention layer를 통해 v^(t+1)를 구함

- 마지막 layer에서는 number, entity에 대한 v^t를 얻음 (나머지 token에서는 extractor의 representation vector가 사용됨)

## 4. Experiments

### 4.1. Dataset and Evaluation Metrics

- DROP
- Exact Match(EM), F1

### 4.2. Baselines

- semantic parsing models(Syn Dep, OpenIE, SRL)
- traditional MRC model(BiDAF, QANet, BERT)
- numerical reasoning module이 있는 MRC model (NAQANet, ALBERT-Calculator, Numnet, Numnet+)

### 4.3. Experiment Settings

- reasoning step에서, T = 4 iterations

### 4.4. Main Results

![Untitled](https://d3i71xaburhd42.cloudfront.net/387d59877a641815d79516a7264ff5d20384c596/7-Table2-1.png)

### 4.5. Ablation Analysis

- `QDGATNH` removes the number type and entity from the graph, and `QDGATNQ` removes question direction from QDGAT and instead uses a normal graph convolution message passing mechanism. `NumNet+` serves as a baseline for reference.

    → QDGAT > `QDGATNH` > `QDGATNQ` > NumNet+

    - 다양한 answer type에 대한 성능 ; Number > Span > Date

### 4.6. Performance on RACENum

- RACENum Dataset에서도 성능 ㄱㅊ

### 4.7. Case Study

- importance of number types
- importance of entity mentions
- importance of question conditioning

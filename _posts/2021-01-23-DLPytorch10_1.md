---
layout: post
title:  "[ëª¨ë‘ë¥¼ ìœ„í•œ ë”¥ëŸ¬ë‹2 Pytorch] CNN with mnist  "
date:   2021-01-23
desc: " "
keywords: "DL, ML"
categories: [Deeplearning]
tags: [DL, ML, pytorch]
icon: icon-html
---

ğŸ³ reference: <ëª¨ë‘ë¥¼ ìœ„í•œ ë”¥ëŸ¬ë‹ 2: pytorch> Lab10


ì´ì œ ë³¸ê²©ì ìœ¼ë¡œ CNN ì‹œì‘!


<br>

# Convolution

![fig](https://miro.medium.com/max/1164/1*0I22V_Kaf-QowUA8IQRw5w.png)

ì´ë¯¸ì§€ ìœ„ì—ì„œ `stride` ë§Œí¼ filterë¥¼ ì´ë™ì‹œí‚¤ë©´ì„œ ê²¹ì³ì§€ëŠ” ë¶€ë¶„ì˜ ê° element ê°’ì„ ê³±í•´ì„œ ëª¨ë‘ ë”í•œ ê°’ì„ ì¶œë ¥ìœ¼ë¡œ í•˜ëŠ” ì—°ì‚°ì„ ì˜ë¯¸í•œë‹¤.


![fig](https://blog.kakaocdn.net/dn/46XO9/btqGeaVthvD/p5yHwE3zk2CPkfdL7j45r1/img.png)


`stride`ëŠ” ì–¼ë§ˆë‚˜ filterë¥¼ ì´ë™í•  ê²ƒì¸ì§€ë¥¼, `padding`ì€ ê°€ì¥ìë¦¬ ì—°ì‚°ì˜ ì†ì‹¤ì„ ë§‰ê¸° ìœ„í•´ ìƒí•˜ì¢Œìš°ì— 0ìœ¼ë¡œ ê°€ë“ì°¬ padë¥¼ ì±„ì›Œì£¼ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.

<br>


ì‚¬ì‹¤ CNNì˜ ê¸°ë³¸ ì›ë¦¬, ê° ìš©ì–´ì˜ ê°œë…(kernel, padding, pooling, ..)ë“¤ì€ [ëª¨ëª¨ë”¥1](https://www.youtube.com/watch?v=Em63mknbtWo&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&index=35)ì—ì„œ í›¨ì”¬ ìì„¸í•˜ê²Œ ë‚˜ì™€ìˆê³ ,

ì´ë²ˆ ëª¨ëª¨ë”¥ 2ì—ì„œëŠ” pytorch ë²„ì „ ìœ„ì£¼ë¡œ ê³µë¶€í–ˆë‹¤.

```python
import pytorch

conv = torch.nn.Conv2d(input_channel, output_channel, kernal_size, ...)
output = conv(input)
```

ì´ ì—°ì‚°ì—ì„œ `input`ì˜ typeì€ torch.Tensor,  inputì˜ shape ì€ (batch size, channel, height, width) ì´ë‹¤.

![fig](https://miro.medium.com/fit/c/1796/541/1*3632mUO_Nf46Kr__ZSFpcg.png)

ì´ë•Œ output size = (input size - filter size + 2*padding)/stride + 1 ì´ë‹¤.

ë§Œì•½ input size = 32x32, filter size(=filter size) = 5x5, stride = 1, padding = 2ì´ë©´,

output size = (32-5+2*2)/1 + 1 = 31 ì´ ëœë‹¤.



```python
import torch

conv = torch.nn.Conv2d(1,1,5,stride = 1, padding = 2)
inputs = torch.Tensor(1,1,32,32)
out = conv(inputs)
print(out.shape)
# torch.Size([1, 1, 32, 32])
```



ë§Œì•½ input size = 32x64, filter size = 5x5, stride = 1, padding = 0ì´ë©´,

output size = 28x60 ì´ ëœë‹¤.



```python
import torch

conv = torch.nn.Conv2d(1,1,5,stride = 1)
inputs = torch.Tensor(1,1,32,64)
out = conv(inputs)
print(out.shape)
# torch.Size([1, 1, 28, 60])
```

<br>

** CNN ì—ì„œëŠ” Perceptronì˜ weight ê°’ìœ¼ë¡œ filterê°€ ì ìš©ëœë‹¤. **

<br>



![fig](https://blog.kakaocdn.net/dn/dzTI4u/btqznO6jsqC/Jhq5kPYymM8Lsh3y7Kvovk/img.png)


poolingë„ ì•„ë˜ì™€ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.



```python
import torch

pool = torch.nn.MaxPool2d(kernal_size, stride, padding , ...)
```



<br>


ì´ì œ ê°€ì¥ ê°„ë‹¨í•œ CNN ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì.


```python
import torch

conv1 = torch.nn.Conv2d(1,1,2,stride = 1)
pool = torch.nn.MaxPool2d(2)

inputs = torch.Tensor(1,1,28,28)
out1 = conv1(inputs)
out2 = pool(out1)
out1.size() #torch.Size([1, 1, 27, 27])
out2.size() #torch.Size([1, 1, 13, 13])
```


<br>

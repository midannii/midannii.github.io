---
layout: post
title:  "[NLP/RE] Matching the Blanks: Distributional Similarity for Relation Learning "
date:   2021-03-19
categories: PaperReview
---

<br>

ì´ë²ˆì— ë¦¬ë·°í•  [ë…¼ë¬¸](https://arxiv.org/abs/1906.03158)ì€,


# Matching the Blanks: Distributional Similarity for Relation Learning

ì´ë‹¤.


<br>

# 1. Introduction

REì—ì„œì˜ ëŒ€í‘œì ì¸ 3ê°€ì§€

1. supervised or distantly supervised RE
    - ì œí•œëœ schemaì—ì„œ textë¡œë¶€í„° relationì„ mappingí•˜ëŠ” ê²ƒì„ í•™ìŠµ
2. openIE
3. universal schema
    - ë‹¤ì–‘í•œ textì™€ schematic relationì„ í¬ìš©

          â†’ arbitrary textual input & arbitrary entity pairë¡œ í™•ì¥ëœ joint representationì„ ìƒì„±

    - but, textì— alignë˜ëŠ” large knowledge graphì— ì˜ì¡´í•¨

ì´ ë…¼ë¬¸ì—ì„œëŠ”, textë¡œë¶€í„° ë°”ë¡œ REë¥¼ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œì‹œ

#Transformer Neural Network architecture

#knowledge graphë‚˜ human annotatorì—†ì´ REí•  ìˆ˜ ìˆìŒ

#ì´ì „ì˜ supervised REë³´ë‹¤ ì„±ëŠ¥ ì¢‹ìŒ

![fig1](https://miro.medium.com/max/1732/1*jHlbU40LukJrHhhGIpuKxg.png)

(1) training dataset

- relation statement ; 2ê°œì˜ marked entityë¥¼ í¬í•¨í•˜ê³  ìˆëŠ” textì˜ block

    â†’ entityë¥¼ [BLANK]ë¡œ ì²˜ë¦¬í•œ relation statementë¡œ training data ë§Œë“¦

(2) training

- Our training procedure takes in pairs of blank-containing relation statements, and has an objective that encourages relation representations to be similar if they range over the same pairs of entities.

(3) after training

- í•™ìŠµëœ REë¥¼ `FewRel task(specific relation)` ì— ì´ìš©í•¨
    - ìƒˆë¡œìš´ domainì—ì„œì˜ relationì— ì ìš©í•´ë³´ë©° í‰ê°€í•¨
    - outperfomí•¨ !
- maching blankë¥¼ í•™ìŠµì‹œí‚¤ê³  labeled dataë¡œ tuningí•´ë„ outperformí•¨ !

# 2. Overview

**Task Definition**

- Let x = [x0 . . . xn] be a sequence of tokens, where x0 = [CLS] and xn = [SEP] are special start and end markers
- Let s1 = (i, j) and s2 = (k, l) be pairs of integers such that 0 < i < j âˆ’ 1, j < k, k â‰¤ l âˆ’ 1, and l â‰¤ n

- relation statement is a triple r = (x, s1, s2)
    - s1,s2 ëŠ” xì˜ entity mentionì„ ê²°ì •
        - sequence [xi . . . xjâˆ’1] , sequence [xk . . . xlâˆ’1]ëŠ” entityë¥¼ mention

- ëª©í‘œ: ì•„ë˜ í•¨ìˆ˜(ê³ ì •ëœ ê¸¸ì´ì˜ ë²¡í„° hrì— relation statementë¥¼ mappingí•´ì¤Œ)ë¥¼ í•™ìŠµ

    ![fig](static/assets/img/blog/papers/MTB_1.png)

    ![fig](static/assets/img/blog/papers/MTB_2.png)

    - ì—”í‹°í‹°(s1, s2) ì˜ relation(x)

**Contributions**

1. Transformer sequence model ìœ„ì— buildëœ fÎ¸(relation encoder)ì— ëŒ€í•´ ë‹¤ì–‘í•œ architecture ì—°êµ¬ (in 3.1)

    â†’ ì´í›„, suprevised trainingìœ¼ë¡œ RE benchmarkì— ì ìš©í•˜ì—¬ architectureë“¤ì„ í‰ê°€

2.  fÎ¸ê°€, entity linked textì˜ formìœ¼ë¡œ distant supervisionìœ¼ë¡œë¶€í„° í•™ìŠµë  ìˆ˜ ìˆìŒì„ ë³´ì„(in 4)

# 3. Architectures for Relation Learning

textë¡œë¶€í„° ë°”ë¡œ relation representationì„ ë§Œë“œëŠ” ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ê²ƒì´ ì²« ëª©í‘œ

**3.1 Relation Classification and Extraction Tasks**

- supervised RE benchmarkì—ì„œ, ë‹¤ì–‘í•œ representationë°©ë²•ì„ í‰ê°€í•¨

    â†’ RE ì¢…ë¥˜ 2ê°€ì§€

    - `fully supervised relation extraction`
        - goal: ì£¼ì–´ì§„ `r(relation statement)` ë¡œë¶€í„° `t(relation type)` ë¥¼ ì˜ˆì¸¡
        - SemEval 2010 Task 8, KBP-37, TACRED ë¡œ í‰ê°€
    - `few-shot relation matching`
        - goal: `rq(query relation statement)` ì— ëŒ€í•œ `tq`  ë¥¼ ì˜ˆì¸¡ (tqâˆˆ{1, ..., K})
            - we are given K sets of N labeled relation statements Sk = {(r0, t0) . . . (rN , tN )} where ti âˆˆ {1 . . . K } is the corresponding relation type.
        - FewRelë¡œ í‰ê°€

**3.2 Relation Representations from Deep Transformers**

- `BERT-Large model` ì´ìš©
- 2ê°€ì§€ modeling question
    - how do we represent entities of interest in the input to BERT
    - how do we extract a fixed length representation of a relation from BERTâ€™s output

![fig](https://i.imgur.com/IzqJyKq.png)

- BERT encoderë¡œ focus span(s1,s2)ì˜ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” option (3ê°€ì§€)
    - standard input (reference)
        - entity span(s1, s2)ì˜ ì–´ë–¤ ëª…ë°±í•œ identification(ì‹ë³„)ì—ë„ access í•  ìˆ˜ ì—†ëŠ” BERT model
        - xê°€ 3ê°œ ì´ìƒì˜ entity mentionì„ ê°€ì§€ê³  ìˆìœ¼ë©´, ì–´ë–¤ 2ê°œì˜ entityì— ì§‘ì¤‘í•´ì•¼ í•˜ëŠ”ì§€ë¥¼ ì•Œ ìˆ˜ ì—†ìŒ

            â†’ ì¦‰, ëª…í™•í•œ entityë¥¼ identification í•˜ì§€ ëª»í•¨

    - `positional embedding`
        - 2ê°€ì§€ì˜ segmentation embedding
            - span s1ì˜ ëª¨ë“  toeknì„ ì¶”ê°€í•¨
            - span s2ì˜ ëª¨ë“  tokenì„ ì¶”ê°€í•¨

        â†’ REì— positional embeddingì„ ì¶”ê°€í•œ ê²ƒê³¼ ë¹„ìŠ·

    - `entity marker tokens`
        - relation statementì—ì„œ, xì—ì„œì˜ê° entity mentionì˜ ì•ê³¼ ëì„ êµ¬ë¶„í•˜ê¸° ìœ„í•´ 4ê°€ì§€ word pieces ë¥¼ ì‚¬ìš©
            - [E1start], [E1end], [E2start], [E2end]
                - x = [x0 ... `[E1start]`xi ... xj-1 `[E1end]` .... `[E2start]` xk .... xl-1 `[E2end]` ... xn] ë¡œ ë‘ê³ , ì´ë¥¼ xëŒ€ì‹  BERTì— token sequenceë¡œ ì…ë ¥í•¨
        - insert tokenì„ ë‹¤ë£¨ê¸° ìœ„í•´, `entity index` ì¸ `s1 = (i+1, j+1)` ê³¼ `s2 = (k+3, l+3)`ì„ ìˆ˜ì •

**3.3 Fixed length relation representation**



###ë‚´ ê¶ê¸ˆì¦; ì™œ fixed length ?? ì–´ë–¤ lengthë¥¼ fixí•˜ëŠ”ì§€ ??  

- BERT encoderë¡œë¶€í„° `hr(fixed length relation representation)` ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•œ 3ê°€ì§€ method

    â†’ transformer networkì˜ ë§ˆì§€ë§‰ hidden layerë¥¼ ì¶”ì¶œí•˜ëŠ” ë° ì˜ì¡´í•¨

    - we define as H = [h0, ...hn] for n = |x| (or |x Ìƒ| if entity marker tokens are used)
    - `[CLS] token`
        - `[CLS] token` ì— correspondingí•˜ëŠ” BERTì˜ output stateê°€ length sentence representationì„ fixí•˜ëŠ”ë° ì“°ì„

            â†’ ì´ ë…¼ë¬¸ì—ì„œ,`[CLS] output` (h0)ì„ì„ first relation representationìœ¼ë¡œ ì ìš©í•  ê²ƒì„

    - `entity mention pooling`
        - hr = < `he1` | `he2` >
            - <a|b>ëŠ” aì™€ bì˜ concatenation
            - 2ê°œì˜ entity mention
                - `he1` = MAXPOOL([hi...hjâˆ’1])
                - `he2` = MAXPOOL([hk...hlâˆ’1])

                â†’ `he1`, `he2` ë¥¼ ì–»ê¸° ìœ„í•´, ê° entity mentionì˜ word pieceì— correspondingí•˜ëŠ” final hidden layerë¥¼ Max-poolingí•´ì„œ `hr` ì„ ì–»ìŒ

    - `entity start state`
        - entity marker ([E1start], .., [E2end]) ë¥¼ ì‚¬ìš©í•œ í›„, relation representationì€ `rh = <hj | hj+2>`

ëª¨ë“  taskì—ì„œ, `ENTITY MARKERS input representation`ê³¼  `ENTITY START output representation` ì´ ì œì¼ ì„±ëŠ¥ì´ ì¢‹ìŒ

![fig](https://bpben.github.io/assets/paper/matchingblanks_1.png)

- modelì˜ input & output architectureë¥¼ defineí•˜ê¸° ìœ„í•´, í•™ìŠµì— ì“°ì´ëŠ” training lossë¥¼ fix í•´ì•¼í•¨
- ëª¨ë“  modelì—ì„œ, Transformer networkì—ì„œì˜ output representationì€,

    linear activationë¥¼ í¬í•¨í•˜ê±°ë‚˜, representationì— ëŒ€í•´ layer normalizationì„ ìˆ˜í–‰í•˜ëŠ”

    FC layerë¡œ ë“¤ì–´ê°

    â†’ Post Transfomer layerì˜ choiceì„ hyperparameterë¡œ ì·¨ê¸‰í•˜ê³ , ê° taskì— ëŒ€í•´ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ layer typeì„ ì‚¬ìš©í•œë‹¤.

**#supervised task**

- we introduce a new classification layer W âˆˆ RKxH where H is the size of the relation representation and K is the number of relation types.
- The classification loss is the standard cross entropy of the softmax of hrWT withrespecttothetruerelationtype.

**#few-shot task**

- we use the dot product between relation representation of the query statement and each of the candidate statements as a similarity score.
- we also apply a cross entropy loss of the softmax of similarity scores with respect to the true class.

# 4. Learning by Matching the Blanks

predefined ontologyë‚˜ relation-labeled training data ì—†ì´ fÎ¸ë¥¼ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•  ì˜ˆì •

- relation statementë¥¼ `r` , `r'`  ë¼ê³  ì •ì˜
    - inner productì¸ `fÎ¸(r)^T fÎ¸(r')`
        - `r` , `r'` ê°€ semantically similar relationì¼ìˆ˜ë¡ ë†’ìŒ & semantically different relationì¼ìˆ˜ë¡ ë‚®ìŒ
- í•™ìŠµí•  ë•Œ, relation labelì„ ì‚¬ìš©í•˜ì§€ ì•Šê³ , entity linked textì—ì„œ fÎ¸ë¥¼ í•™ìŠµ
    - ì¤‘ë³µì´ ë§ì€ web textì—ì„œ, s1ê³¼ s1'ì´ ë™ì¼í•œ entityë¥¼ referí•˜ê³ ,  s2ì™€ s2'ì´ ë™ì¼í•œ entityë¥¼ referí•  ë•Œ,

        â†’  **r = (x, s1, s2)ê°€ râ€² = (xâ€², sâ€²1, sâ€²2)ì™€ ë™ì¼í•œ semantic relationì„ encodeí•  ê°€ëŠ¥ì„±ì´ ë†’ìŒì„ ì´ìš©í•¨**

**4.1 Learning Setup**

- binary classifier

    ![binaryClassifier](static/assets/img/blog/papers/MTB_3.png)

    - E ; predefined set of entities
    - D = [(r0,e01,e02)...(rN,eN1 ,eN2 )] be a corpus of relation statements that have been labeled with two entities ei1 âˆˆ E and ei2 âˆˆ E
    - Each item in D is created by pairing the relation statement ri with the two en- tities ei1 and ei2 corresponding to the spans si1 and si2
    - fÎ¸(relation statement encoder) ; 2ê°œì˜ relation statementê°€ ê°™ì€ relationì„ encodeí•˜ê³  ìˆëŠ”ì§€ë¥¼ ê²°ì •í•˜ëŠ”ë° ì‚¬ìš©

- loss

    ![loss](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTcN2Z9ou9wNUakeAjhRbz1QAM6ht5-8hIQFA&usqp=CAU)

    - Î´e,eâ€² is the Kronecker delta that takes the value 1 iff e = eâ€², and 0 otherwise.
    - ì´ lossëŠ”, entity linking systemì— ì˜í•´ minizedë  ìˆ˜ ìˆë‹¤.

**4.2 Introducing Blanks**

- modified corpus D Ìƒ:

    ![D](static/assets/img/blog/papers/MTB_D.png)

    - ë‹¨ìˆœíˆ linking systemë§Œ ì¬í•™ìŠµí•˜ëŠ” ê²ƒì„ í”¼í•˜ê¸° ìœ„í•´ ë„ì…í•¨
    - ì´ Dì—ëŠ”, í•œë‘ê°œì˜ entityê°€ [BLANK] symbolë¡œ ëŒ€ì²´ëœ ri = (x Ìƒi, si1, si2)ê°€ ìˆë‹¤.
    - íŠ¹íˆ,x Ìƒì—ëŠ” í™•ë¥  Î±ë¡œ s1,s2ì— ì˜í•´ ì •ì˜ëœ spanì„ í¬í•¨í•˜ë©°, spanì€ [BLANK] symbolë¡œ ëŒ€ì²´ë˜ì–´ìˆë‹¤.

â†’ We hypothesize that training on D Ìƒ will result in a fÎ¸ that encodes the semantic relation between the two possibly elided entity spans !!

**4.3 Matching the Blanks (MTB) Training**

BERTì˜ training setupê³¼ ë¹„ìŠ·í•˜ê²Œ êµ¬ì„±í•¨

- 2ê°œì˜ lossê°€ ë™ì‹œì— ì‚¬ìš©ë¨ ; `masked language model loss` & `the matching the blanks loss`

- training corpus ìƒì„±

    â†’ English Wikipediaì—ì„œ textì¶”ì¶œ â†’  `off-the-shelf entity linking system` ìœ¼ë¡œ text spanì„ idì™€ í•¨ê»˜ í‘œì‹œ â†’ relation statement ì¶”ì¶œ

    - ì´ë•Œ, biasë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ entityë¥¼ í¬í•¨í•˜ëŠ” relation statementë¥¼ random sampling & ê°œìˆ˜ ì œí•œ

    - (D Ìƒ)ë¥¼ ì¤„ì´ê¸° ìœ„í•´,  `noise-contrasitive estimation`  ì„ ì‚¬ìš©í•¨

        â†’ ê°™ì€ entityë¥¼ ê°€ì§€ê³  ìˆëŠ” ëª¨ë“  relation statementì˜ positive pairë¥¼ ê³ ë ¤í•˜ì—¬, ê°™ì€ entityìŒì„ ê°€ì§€ì§€ ì•ŠëŠ” ëª¨ë“  relation statementë¥¼ í•©í•¨

        - ê·¸ ëŒ€ì‹ , ì „ì²´ relation statementì—ì„œ random samplingí•œ relation statementì´ë‚˜ í•˜ë‚˜ì˜ entityë§Œ ê³µí†µìœ¼ë¡œ ê°€ì§€ëŠ” **relation statementë¥¼**   negative samplingí•¨
        - `hard negative` setë¥¼ í¬í•¨í•¨
            - We include the second set â€˜hardâ€™ negatives to account for the fact that most randomly sampled relation statement pairs are very unlikely to be even remotely topically related, and we would like to ensure that the training procedure sees pairs of relation statements that refer to similar, but different, relations.

        â†’ Î± = 0.7ìœ¼ë¡œ entityë¥¼ [BLANK] symbolë¡œ ëŒ€ì²´

# 6. Conclusion & Future Work

ìš°ë¦¬êº¼ ì„±ëŠ¥ ì¢‹ë‹¤!!!! ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³

<br>

---
layout: post
title:  "[NLP] Blenderbot 2.0 ; Beyond Goldfish Memory: Long-Term Open-Domain Conversation "
date:   2021-09-08
desc: " "
keywords: "DL, ML"
categories: [Deeplearning]
tags: [DL, ML]
icon: icon-html
---


## Abstract

- we collect and release a human-human dataset consisting of multiple chat sessions

- We show how existing models trained on existing datasets perform poorly in this long-term conversation setting in both automatic and human evaluations,

- we study long-context models that can perform much better.

- we find retrieval-augmented methods and methods with an ability to summarize and recall previous conversations outperform the standard encoder-decoder architectures currently considered state of the art.

<br>


## 1. Introduction

we study methods for long-term open-domain conversation. As to the best of our knowledge no public domain task exists to study such methods

we collect and release a new English dataset, entitled Multi-Session Chat (MSC). The dataset consists of human-human crowdworker chats over 5 sessions

- ê° sessionì€ ìµœëŒ€ 14ê°œì˜ utteranceë¡œ ì´ë£¨ì–´ì ¸ ìˆìŒ

- ì´ì „ sessionì—ëŠ” ì´í›„ì˜ ëŒ€í™”ì— ìœ ìš©í•  ìˆ˜ ìˆëŠ” personal pointì˜ summarizationì´ annotateë¨

â†’ ì´ë¥¼ fine-tuningì— ì ìš©í•¨


We study the performance of two long-context conversational architectures on this task:

(i) retrieval-augmented generative models

(ii) a proposed read-write memory-based model that summarizes and stores conversation on the fly.


<br>


## 3. Multi-Session Chat


ìš°ë¦¬ê°€ ì‚¬ìš©í•œ datasetì€ MSC(multi-session chat)

- " individual chat session is long"  == ì¤‘ê°„ì— ëª‡ì‹œê°„ ~ ë©°ì¹  paused ë¨

      - ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ multi-session long conversation setupì„ ê³ ë ¤í•¨


- Session 1ì—ì„œëŠ” ê¸°ì¡´ PERSONACHATì¸ ì§§ì€ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì²˜ìŒ ë§Œë‚œ ë‘ ì‚¬ëŒì˜ ê°„ëµí•œ ì •ë³´ë§Œ ì„œë¡œ ë‚˜ëˆ„ëŠ” ëŒ€í™” íƒœìŠ¤í¬ë¡œ ì§„í–‰ì´ ë©ë‹ˆë‹¤.

- Session 2~4ê¹Œì§€ëŠ” ì •í•´ì§„ ì‹œê°„ì˜ term(1~7ì‹œê°„ ë‹¨ìœ„ ë˜ëŠ”1~7ì¼ ë‹¨ìœ„)ì„ ë‘ê³ , ê¸°ì¡´ personaë¥¼ ìœ ì§€í•˜ê³  ì´ì „ì— í–ˆë˜ ëŒ€í™”ë¥¼ ë°˜ì˜í•œ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ê²Œ í•©ë‹ˆë‹¤. ë§ˆì¹˜ ì´ì „ì— ëŒ€í™”í•˜ë‹¤ê°€ ì‹œê°„ì´ í˜ëŸ¬ ë‹¤ì‹œ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ëŠ” ë‘ ì‚¬ëŒì²˜ëŸ¼ ì£¼ì œê°€ í™•ëŒ€ë  ë•Œë„ ì´ì „ì— ë‚˜ëˆˆ ëŒ€í™”ì™€ ì¼ê´€ì„±ì´ ìˆê²Œ ëŒ€í™”ë¥¼ ì§„í–‰í•˜ê²Œ í•©ë‹ˆë‹¤.

- Conversation summaries (í™•ì¥ëœ persona) ì›Œì»¤ê°„ì— ì´ì „ ëŒ€í™”ë¥¼ ë³¼ ìˆ˜ë„ ìˆê³ , ì´ì „ íˆìŠ¤í† ë¦¬ì˜ íŒŒì•…ì´ ê°€ëŠ¥í•œ í™˜ê²½ì„ ì£¼ë”ë¼ë„ ì‚¬ëŒì€ ì œí•œëœ ì‹œê°„ë‚´ì— ê·¸ ì •ë³´ë¥¼ ì½ê³  í™œìš©í•˜ê¸°ëŠ” í•œê³„ê°€ ìˆê¸° ë§ˆë ¨ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ê° sessionì—ì„œ ì¤‘ìš” í¬ì¸íŠ¸ë¥¼ ê¸°ë¡í•˜ê³  ìš”ì•½í•˜ì—¬ ëŒ€í™”ì˜ ì°¸ê³  ìë£Œë¡œ í™œìš©í•˜ê²Œ í•©ë‹ˆë‹¤.

- Dataset staticsë¥¼ ë³´ë©´ ì´ì „ì— êµ¬ì¶•í•œ ì§§ì€ 2.6 ~ 14.77ì˜ ì§§ì€ í„´ì— ë¹„í•´ MSCëŠ” 53 ~ 66í„´ ë“±ì˜ ê¸´ ë°œí™”ìˆ˜ë¥¼ ê°€ì§‘ë‹ˆë‹¤.

ëª‡ì‹œê°„ ~ ë©°ì¹  pauseëœ í›„ ì¬ê°œí• ë•Œ, í™”ìëŠ” (i) ì´ì „ ì£¼ì œì— ëŒ€í•´ ê³„ì† ì´ì•¼ê¸°í•˜ê±°ë‚˜ (ii) ê³¼ê±° ê³µìœ  ê¸°ë¡ì—ì„œ ë‹¤ë¥¸ ì£¼ì œë¥¼ êº¼ë‚´ê±°ë‚˜ (iii) ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ë‹¤ì‹œ ì‹œì‘í•¨

- CrowdWorkers + 1155ëª…ì˜ Personas ì‚¬ìš©; ì²«ë²ˆì§¸ ëŒ€í™” ì´í›„ ì‹œê°„ì´ íë¥¸ ë’¤ ëŒ€í™” í•˜ë„ë¡ .. or ê·¸ëŸ° ì²™

      - 4000 episodes with 3 sessions, and 1001 episodes with 4 sessions.



<br>


## 4. # 4. Modeling Multi-Session Chat

- We consider using the BST 2.7B parameter model from Blender-Bot as an initial pre-trained model, which we then fine-tune on the Multi-Session Chat task.
- Encoder Truncation
    - ê¸°ì¡´ì— encodingì—ì„œ 128 tokenì´ì—ˆë˜ BST 2.7Bë³´ë‹¤ ë” í° inputì„ ë°›ë„ë¡ ; 256, 512 or 1024 tokens

## 4.2. Retrieval-Augmentation

- a retrieval system is used to find and select part of the context to be included in the final encoding which is attended to by the decoder.

    ** FiD, RAG ì„¤ëª…; [https://ratsgo.github.io/insight-notes/docs/qa/answerer#retrieval-augmented-generation](https://ratsgo.github.io/insight-notes/docs/qa/answerer#retrieval-augmented-generation)

ê²€ìƒ‰ ì‹œìŠ¤í…œ(retrieval system)ì€ ë””ì½”ë”ì— ì˜í•´ ì œê³µë˜ëŠ” ìµœì¢… ì¸ì½”ë”©ì— í¬í•¨ë  ì»¨í…ìŠ¤íŠ¸ì˜ ì¼ë¶€ë¥¼ ì°¾ì•„ ì„ íƒí•˜ëŠ”ë° ì‚¬ìš©

- RAG(Retrieval-Augmented Generation)

    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d8a8f8b5-b432-45c0-910a-c48b0316f7b6/Untitled.png)

    - RAG utilizes Neural-retriever-in-loop which is itself a Transformer
    - ê²€ìƒ‰í•  ë¬¸ì„œëŠ” ê°€ì¥ ê°€ê¹Œìš´ FAISS indexì— ì €ì¥
        - Dense Passage Retrieval(DPR) modelì´ FAISS indexì—ì„œ ê²€ìƒ‰ â†’ ìƒìœ„ Nê°œ í›„ë³´ì— ì ìˆ˜ ë§¤ê¹€ (document-context pair ì´ìš©)
    - Transformer bi-encoder modelì„ ì‚¬ìš©í•˜ì—¬ ì ìˆ˜ ë§¤ê¹€
    - end-to-end train
- FiD(Fusion in Decoder)

    ![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-15 á„‹á…©á„Œá…¥á†« 12.20.19.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/cfb33b1b-2218-43c7-9cc1-2f66dc2fb1a3/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-08-15_á„‹á…©á„Œá…¥á†«_12.20.19.png)

    - FiDì˜ ë‹µë³€ ìƒì„± ë°©ì‹; ì¿¼ë¦¬ì™€ì˜ ê´€ë ¨ì„±ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ Nê°œ ì…ë ¥ì„ ë§Œë“¤ê³  ê°ê° ì¸ì½”ë”ì— íƒœì›Œì„œ ë²¡í„°ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤. ì´ ğ‘ ê°œì˜ ì¸ì½”ë”© ë²¡í„°ë“¤ì„ í•©ì³(concatenate) ë””ì½”ë”ì— ë„£ê³  ë‹µë³€ì„ ìƒì„±
- FiD-RAG
    - pre-trained retriever (RAG-trained retriever)
    - FiDë¥¼ ê³ ë ¤í•œ ë°©ë²•ì„; returnëœ ìƒìœ„ Nê°œì˜ ë¬¸ì„œ ê°ê°ì€ ì»¨í…ìŠ¤íŠ¸ ì•ì— ì¶”ê°€ë˜ê³  ì¸ì½”ë”ì— ì˜í•´ ë³„ë„ë¡œ ì¸ì½”ë”©ë˜ë©°, ë§ˆì§€ë§‰ìœ¼ë¡œ ëª¨ë“  ê²°ê³¼ê°€ concatë¨.

        ê·¸ëŸ° ë‹¤ìŒ ë””ì½”ë”ëŠ” ì´ëŸ¬í•œ ì¸ì½”ë”©ì— ì£¼ì˜í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìƒì„±

- Retriever and Documents
    - memoryì˜ ëª¨ë“  í•­ëª©ì„ DPR modelë¡œ encodingí•˜ëŠ” Vectorì— ì €ì¥ (FAISS ì—ì„œëŠ” dense vector ì‚¬ìš©)

        â†’ dialog contextê°€ ì£¼ì–´ì§€ë©´ bi-encoderë¥¼ ì‚¬ìš©í•˜ì—¬ ê° memoryì— ì ìˆ˜ ë§¤ê¹€ & generationì„ ìœ„í•´ ìƒìœ„ Nê°œ ì‚¬ìš©

        - ë³¸ ì—°êµ¬ì—ì„œ memoryëŠ” ëŒ€í™” Historyì—ì„œ ë‚˜ì˜¨ dialog utterence

        â†’ chunk(passage) í¬ê¸°ë¥¼ hyperparameterë¡œ í•˜ì—¬, utteranceë¥¼ separate documentë¡œ encodingí•˜ê±°ë‚˜, ì „ì²´ session ë° session summaryë¥¼ separate documentë¡œ encoding

â†’ ë‹¨ì  !!

- The retrieval-augmentation model  retrieves from the set of past dialogues. Simply storing historical context in the memory in its raw form is a simple approach that is often used elsewhere in the literature, e.g. in question answering or knowledge-grounded dia- logue. However, those approaches have two potential drawbacks:

    (i) there is a lot of context to store, and hence retrieve from;

    (ii) no processing has been done on that content, so the reading, retrieving and combining to finally generate leaves a lot of work for the model to do.

### 4.3. Memory Augmentation's Summary

- retrieval-augmentation modelì˜ ë‹¨ì ì„ ë³´ì™„í•˜ê¸° ìœ„í•´, We propose instead a memory augmentation that first summarizes the pertinent knowledge and only stores that instead in an attempt to solve both problems. (ë§ˆì§€ë§‰ ëŒ€í™” ì°¨ë¡€ì— í¬í•¨ëœ ìƒˆë¡œìš´ ê´€ë ¨ ì •ë³´ë¥¼ ìš”ì•½)
- The procedure involves two main components:
    1. An `encoder-decoder abstractive summarizer` that takes as input the dialogue history with the goal of summarizing any new pertinent information contained in the last dialogue turn. This includes the case of deciding that no new information should be stored in the memory. When found, the summarized knowledge is added to the long-term memory.
        - we can use the human annotated data from our newly collected MSC task to know what summaries to generate. We thus train a supervised encoder-decoder model to produce summaries.

        ì¦‰, ë§ˆì§€ë§‰ ëŒ€í™”ì— í¬í•¨ëœ ìƒˆë¡œìš´ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¥ê¸°ê¸°ì–µ ì¥ì¹˜ì— ì¶”ê°€í•˜ëŠ” ê¸°ëŠ¥;  `SumMem model`

    2. A `memory-augmented generator` that takes the dialogue context and access to the long-term memory, and then generates the next response. (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì™€ ì¥ê¸° ê¸°ì–µì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ê³  ë‹¤ìŒ ì‘ë‹µì„ ìƒì„±)
        - we can use the same systems as presented in subsection 4.2 to both retrieve from the summarization memories, and to finally generate an appropriate response.

        ì¦‰, ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì™€ ì¥ê¸° ë©”ëª¨ë¦¬ì— ì ‘ê·¼í•˜ì—¬ ë‹¤ìŒ ë‹µë³€ì„ ìƒì„±í•˜ëŠ”ë° ì‚¬ìš©


<br>
